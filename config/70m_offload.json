{
    "dim": 512,
    "n_layers": 6,
    "n_heads": 8,
    "vocab_size": 50304,
    "hidden_dim": 2048,
    "norm_eps": 1e-5,
    "max_seq_len": 2048,
    "rope_theta": 10000,
    "dropout": 0.0,
    "flash_attn": true,
    "use_moe": false,
    "num_experts_per_tok": 2,
    "n_routed_experts": 4,
    "n_shared_experts": true,
    "scoring_func": "softmax",
    "aux_loss_alpha": 0.1,
    "seq_aux": true,
    "norm_topk_prob": true,
    "n_routed_mole_experts": 2,
    "offload_tok_embbedings": true,
    "is_profile": false,
    "tokenizer_path": "EleutherAI/pythia-70m-deduped",
    "max_length": 2049,
    "batch_size": 8,
    "warmup_steps": 1500,
    "checkpoint_steps": 1000,
    "max_lr": 1e-3,
    "weight_decay": 0.0001,
    "max_samples": 47700000,
    "embedding_init_std": 1e-5,
    "optimizer_type": "adamw"
}
